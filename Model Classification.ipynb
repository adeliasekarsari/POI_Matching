{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1038264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adelia\\AppData\\Local\\Temp\\ipykernel_21808\\3878294190.py:1: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn import over_sampling\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de90f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification(model, avg = 'binary'):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    y_pred_proba_train = model.predict_proba(X_train)\n",
    "    \n",
    "    print(\"Accuracy (Test Set): %.6f\" % accuracy_score(y_test, y_pred))\n",
    "    print(\"Accuracy (Train Set): %.6f\" % accuracy_score(y_train, y_pred_train))\n",
    "    print(\"Precision (Test Set): %.6f\" % precision_score(y_test, y_pred, average = avg))\n",
    "    print(\"Precision (Train Set): %.6f\" % precision_score(y_train, y_pred_train, average = avg))\n",
    "    print(\"Recall (Train Set): %.6f\" % recall_score(y_train, y_pred_train, average = avg))\n",
    "    print(\"Recall (Test Set): %.6f\" % recall_score(y_test, y_pred, average = avg))\n",
    "    print(\"F1-Score (Train Set): %.6f\" % f1_score(y_train, y_pred_train, average = avg))\n",
    "    print(\"F1-Score (Test Set): %.6f\" % f1_score(y_test, y_pred, average = avg))\n",
    "\n",
    "    #score = cross_validate(model, X_over, y_over, cv=5, scoring='roc_auc', return_train_score=True)\n",
    "    #print('roc_auc (crossval train): '+ str(score['train_score'].mean()))\n",
    "    #print('roc_auc (crossval test): '+ str(score['test_score'].mean()))\n",
    "def show_feature_importance(model):\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.xlabel('score')\n",
    "    plt.ylabel('feature')\n",
    "    plt.title('feature importance score')\n",
    "\n",
    "def show_best_hyperparameter(model):\n",
    "    print(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930462a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"sampling.xlsx\")\n",
    "df['id_model'] = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786d5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns = ['cleaned_poi_name','cleaned_nama_merchant','similarity',\n",
    "#                           'tfidf_similarity', 'levenshtein_similarity'\n",
    "                         ])\n",
    "data = data.sample(350).copy()\n",
    "\n",
    "X = data.fillna(0).drop(columns = ['id_model','target'])\n",
    "y = data.fillna(0)['target']\n",
    "\n",
    "X_over, y_over = over_sampling.SMOTE().fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822a1d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test Set): 0.866667\n",
      "Accuracy (Train Set): 1.000000\n",
      "Precision (Test Set): 0.866667\n",
      "Precision (Train Set): 1.000000\n",
      "Recall (Train Set): 1.000000\n",
      "Recall (Test Set): 0.866667\n",
      "F1-Score (Train Set): 1.000000\n",
      "F1-Score (Test Set): 0.866667\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier # import decision tree dari sklearn\n",
    "dt = DecisionTreeClassifier(random_state=42) # inisiasi object dengan nama dt\n",
    "dt.fit(X_train, y_train) # fit model decision tree dari data train\n",
    "eval_classification(dt, avg = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b1ee868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test Set): 0.962\n",
      "Accuracy (Train Set): 1.000\n",
      "Precision (Test Set): 0.962\n",
      "Precision (Train Set): 1.000\n",
      "Recall (Train Set): 1.000\n",
      "Recall (Test Set): 0.962\n",
      "F1-Score (Train Set): 1.000\n",
      "F1-Score (Test Set): 0.962\n"
     ]
    }
   ],
   "source": [
    "#randomforest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "eval_classification(rf, avg = 'micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18b3042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1\n",
       "0  92    0\n",
       "1   0  153"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, y_pred_train)\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "389ab75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test Set): 0.933\n",
      "Accuracy (Train Set): 0.904\n",
      "Precision (Test Set): 0.933\n",
      "Precision (Train Set): 0.904\n",
      "Recall (Train Set): 0.904\n",
      "Recall (Test Set): 0.933\n",
      "F1-Score (Train Set): 0.904\n",
      "F1-Score (Test Set): 0.933\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning Randomforest\n",
    "\"\"\"\n",
    "    n_estimators=100,\n",
    "    *,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0,\n",
    "    max_samples=None,\n",
    "\"\"\"\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "#Menjadikan ke dalam bentuk dictionary\n",
    "hyperparameters = {\n",
    "                    'n_estimators' : [int(x) for x in np.linspace(10, 30, num = 10)],\n",
    "                    'criterion':[\"gini\", \"entropy\", \"log_loss\"],\n",
    "                    'max_depth' : [int(x) for x in np.linspace(8, 15, num = 50)],\n",
    "                    'min_samples_split' : [int(x) for x in np.linspace(8, 20, num = 9)],\n",
    "                    'min_samples_leaf':[int(x) for x in np.linspace(10, 30, num = 9)],\n",
    "            \n",
    "                    }\n",
    "\n",
    "# Init\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_tuned = RandomizedSearchCV(rf, hyperparameters, cv=5, random_state=42, scoring='roc_auc')\n",
    "rf_tuned.fit(X_train,y_train)\n",
    "\n",
    "# Predict & Evaluation\n",
    "eval_classification(rf_tuned, avg = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d217e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1\n",
       "0  86    9\n",
       "1  12  173"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf_tuned.predict(X_test)\n",
    "y_pred_train = rf_tuned.predict(X_train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, y_pred_train)\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8686a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_tuned, open('model_v1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf50b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = pickle.load(open('model_v1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6194573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df_test = df[~df['id_model'].isin(data['id_model'].tolist())]\n",
    "# df_test = df.sample(100)\n",
    "X_test = df_test[X.columns.tolist()].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78ddacd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adelia\\AppData\\Local\\Temp\\ipykernel_4752\\2371292965.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['target_model'] = predict\n"
     ]
    }
   ],
   "source": [
    "predict = pickled_model.predict(X_test)\n",
    "df_test['target_model'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72851c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 87\n",
      "True Negatives (TN): 58\n",
      "False Positives (FP): 3\n",
      "False Negatives (FN): 2\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "target = df_test['target'].tolist()\n",
    "target_model = df_test['target_model'].tolist()\n",
    "cm = confusion_matrix(target, target_model)\n",
    "# Extract TN, FP, FN, TP\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Display the results\n",
    "print(f'True Positives (TP): {TP}')\n",
    "print(f'True Negatives (TN): {TN}')\n",
    "print(f'False Positives (FP): {FP}')\n",
    "print(f'False Negatives (FN): {FN}')\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
